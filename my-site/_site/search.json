[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Projects",
    "section": "",
    "text": "Causality\n\n\nStatistical Significance Analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCommon Search Algorithms Applied to Mazes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDesigning a Unified KPI Framework for Enterprise Decision-Making\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMarketing A/B Test\n\n\nStatistical Significance Analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredicting Marketing Success\n\n\nAn Analysis of Education and Income as Predictors of Campaign Receptivity\n\n\n\n\n\n\n\n\nYour Name\n\n\n\n\n\n\n\n\n\n\n\n\nProject One: Housing Price Predictor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTwo\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnveiling Hidden Patterns\n\n\nClustering and Statistical Validation of Walmart Store Sales\n\n\n\n\n\n\n\n\nYour Name\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "HELLO, I‚ÄôM NICK.",
    "section": "",
    "text": "LINKEDIN GITHUB DOWNLOAD RESUME"
  },
  {
    "objectID": "index.html#tech-stack",
    "href": "index.html#tech-stack",
    "title": "HELLO, I‚ÄôM NICK.",
    "section": "üõ†Ô∏è Tech Stack",
    "text": "üõ†Ô∏è Tech Stack\n\n\n\n‚å®Ô∏è Executive Decision Support & KPI Governance\nTranslating complex commercial and product data into trusted executive decisions\n\nTrusted advisor to C-suite and VP leadership on revenue architecture and KPI design\n\n\nOwnership of SSOT logic for executive MBRs across global sales organizations\n\n\nResolution of cross-functional metric conflicts through shared definitions and governance\n\n\nDecision framing for quota management, forecasting, and long-range planning\n\n\n\n\n\n\n‚òÅÔ∏è Forecasting, Experimentation & Risk Modeling\nEnabling proactive decisions under uncertainty\n\nProbabilistic demand and revenue forecasting for capacity and budget planning\n\n\nValidation frameworks to support high-stakes resource allocation decisions\n\n\nScenario analysis and risk modeling for operational optimization\n\n\nTools: Python, SQL, scikit-learn, Prophet\n\n\n\n\n\n\n\nüß™ Productized Analytics & Data Platforms\nBuilding analytics systems that scale decision-making\n\nArchitected centralized analytics platforms serving sales, product, and operations\n\n\nProductized Python- and SQL-based analytics used by hundreds of stakeholders\n\n\nEnabled self-service analytics while preserving data quality and governance\n\n\nTools: BigQuery, Snowflake, dbt, Python, Airflow-style orchestration\n\n\n\n\n\n\nüìä Data Architecture, Quality & Governance\nEnsuring trust, scale, and consistency in enterprise analytics\n\nMetric standardization, lineage, and metadata governance\n\n\nDesign of scalable data models for petabyte-scale datasets\n\n\nPrivacy-safe analytics architecture and compliance leadership\n\n\nTools: dbt, Snowflake, BigQuery, SQL optimization/div&gt;\n:::\n\nüìä Cross-Functional Leadership & Influence\nLeading through influence across product, engineering, and commercial teams &lt;div class=Founding analytics lead for new orgs and initiatives\n\n\nAlignment of Sales, Finance, Product, and Engineering on shared data strategy\n\n\nTechnical mentorship and enablement for global teams\n\n\nOrg-wide standards and best-practice development\n\n\n\nüìä Strategic Translation & Storytelling\nTurning analysis into clear, defensible narratives &lt;div class=‚Äúskill-pill‚ÄùExecutive-level decision memos and readouts\n\n\n\nTradeoff framing and scenario communication\n\n\nTranslation of statistical uncertainty into business action\n\n\nStakeholder-ready storytelling for technical and non-technical audiences"
  },
  {
    "objectID": "index.html#featured-projects",
    "href": "index.html#featured-projects",
    "title": "HELLO, I‚ÄôM NICK.",
    "section": "üöÄ FEATURED PROJECTS",
    "text": "üöÄ FEATURED PROJECTS"
  },
  {
    "objectID": "index.html#the-mission",
    "href": "index.html#the-mission",
    "title": "NICHOLAS MICHAUD",
    "section": "üí° The Mission",
    "text": "üí° The Mission\nI bridge the gap between complex raw data and actionable business strategy. Specializing in predictive modeling and automated reporting pipelines using Python and R."
  },
  {
    "objectID": "index.html#stack",
    "href": "index.html#stack",
    "title": "NICHOLAS MICHAUD",
    "section": "üõ†Ô∏è Stack",
    "text": "üõ†Ô∏è Stack\n\nLanguages: Python, R, SQL\nModels: XGBoost, PyTorch\nViz: Plotly, ggplot2"
  },
  {
    "objectID": "index.html#current-focus",
    "href": "index.html#current-focus",
    "title": "NICHOLAS MICHAUD",
    "section": "üöÄ Current Focus",
    "text": "üöÄ Current Focus\nCurrently building a Bayesian inference engine for marketing attribution. Read the latest technical write-up ‚Üí"
  },
  {
    "objectID": "index.html#featured-projects-1",
    "href": "index.html#featured-projects-1",
    "title": "HELLO, I‚ÄôM NICK.",
    "section": "FEATURED PROJECTS",
    "text": "FEATURED PROJECTS"
  },
  {
    "objectID": "index.html#project-one",
    "href": "index.html#project-one",
    "title": "HELLO, I‚ÄôM NICK.",
    "section": "PROJECT ONE",
    "text": "PROJECT ONE\nA Data Science Tool\nVIEW PROJECT"
  },
  {
    "objectID": "index.html#project-two",
    "href": "index.html#project-two",
    "title": "HELLO, I‚ÄôM NICK.",
    "section": "PROJECT TWO",
    "text": "PROJECT TWO\nGlobal Diagnostic & ETL Engine | Google An interactive dashboard using PyTorch and Shiny. Visualizes how weights change during backpropagation in real-time.\nVIEW PROJECT"
  },
  {
    "objectID": "index.html#project-three",
    "href": "index.html#project-three",
    "title": "HELLO, I‚ÄôM NICK.",
    "section": "PROJECT THREE",
    "text": "PROJECT THREE\nNeural Network Viz An interactive dashboard using PyTorch and Shiny. Visualizes how weights change during backpropagation in real-time.\nVIEW PROJECT"
  },
  {
    "objectID": "index.html#currently-building",
    "href": "index.html#currently-building",
    "title": "HELLO, I‚ÄôM NICK.",
    "section": "üõ†Ô∏è CURRENTLY BUILDING",
    "text": "üõ†Ô∏è CURRENTLY BUILDING\nAn interactive dashboard using PyTorch and Shiny. Visualizes how weights change during backpropagation in real-time. I‚Äôm currently deep-diving into **Large Language Model fiom RAG pipeline for local documentation. VIEW PROJECT"
  },
  {
    "objectID": "index.html#currently-building-1",
    "href": "index.html#currently-building-1",
    "title": "HELLO, I‚ÄôM NICK.",
    "section": "üõ†Ô∏è CURRENTLY BUILDING",
    "text": "üõ†Ô∏è CURRENTLY BUILDING\nI‚Äôm currently deep-diving into Large Language Model fine-tuning and building a custom RAG pipeline for local documentation."
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "HELLO, I‚ÄôM NICK.",
    "section": "üíº EXPERIENCE",
    "text": "üíº EXPERIENCE"
  },
  {
    "objectID": "posts/one.html",
    "href": "posts/one.html",
    "title": "Project One: Housing Price Predictor",
    "section": "",
    "text": "Data Science ‚Ä¢ Python ‚Ä¢ Scikit-Learn \n\nBUSINESS CASE"
  },
  {
    "objectID": "posts/one.html#the-challenge",
    "href": "posts/one.html#the-challenge",
    "title": "Project One: Housing Price Predictor",
    "section": "THE CHALLENGE",
    "text": "THE CHALLENGE\nThis project solves the problem of‚Ä¶\nVIEW GITHUB REPO BACK TO ALL PROJECTS"
  },
  {
    "objectID": "posts/one.html#exploratory-data-analysis",
    "href": "posts/one.html#exploratory-data-analysis",
    "title": "Project One: Housing Price Predictor",
    "section": "üìà EXPLORATORY DATA ANALYSIS",
    "text": "üìà EXPLORATORY DATA ANALYSIS\n\n\n\nCorrelation matrix showing the relationship between square footage and price.\n\n\nInsight: We found that location had a 3x higher impact on price than the number of bedrooms."
  },
  {
    "objectID": "posts/one.html#technical-implementation",
    "href": "posts/one.html#technical-implementation",
    "title": "Project One: Housing Price Predictor",
    "section": "üíª TECHNICAL IMPLEMENTATION",
    "text": "üíª TECHNICAL IMPLEMENTATION\n\nTHE LOGIC\nI used a StandardScaler to ensure the housing features were on the same scale, which improved the model convergence time.\n\n\nüêç PREPROCESSINGüêç PRNGsdsddüêç Psdsdsd\n\n\n\nmodel_preprocessing.py\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n\n\n01_LOAD_DATA.PY\n\n    THIS IS THE COE FOR PART 2\n\n\n\n01_LOA.PY\n\n    THIS IS THE COE FOR PART 3\n\n\n\n\nüí° LESSONS LEARNED\nThis section will now render correctly because the code block above it is closed.\n\n\nüí° LESSONS LEARNED\n\nFeature Engineering: Simple features often beat complex ones.\nData Cleaning: Spending 80% of the time on cleaning was worth it."
  },
  {
    "objectID": "index.html#languages-eng",
    "href": "index.html#languages-eng",
    "title": "HELLO, I‚ÄôM NICK.",
    "section": "‚å®Ô∏è LANGUAGES & ENG",
    "text": "‚å®Ô∏è LANGUAGES & ENG\n\nLANGUAGES: SQL (EXPERT) ‚Ä¢ PYTHON ‚Ä¢ JS LIBRARIES: PANDAS ‚Ä¢ NUMPY ‚Ä¢ SCIKIT-LEARN ‚Ä¢ TENSORFLOW\n\nETL\n\n\nGIT\n\n\nWEB APPS"
  },
  {
    "objectID": "index.html#ms-in-data-science",
    "href": "index.html#ms-in-data-science",
    "title": "HELLO, I‚ÄôM NICK.",
    "section": "MS in Data Science",
    "text": "MS in Data Science\nFocus on Machine Learning."
  },
  {
    "objectID": "index.html#freewheel",
    "href": "index.html#freewheel",
    "title": "HELLO, I‚ÄôM NICK.",
    "section": "FREEWHEEL",
    "text": "FREEWHEEL\n\nLead Analyst ‚Ä¢ 2025-Present\n\nFounded, architected, and governed the analytics function for a 0-to-1 Commercial Operations business unit. Served as the primary C-Suite advisor to the Chief Commercial Officer (CCO), directing strategic decision support and scaling performance measurement across six sales organizations. &gt; &gt; &gt; Architected the end-to-end Sales Performance Monitoring ecosystem, deploying real-time pacing and KPI dashboards across six distinct sales organizations. This initiative streamlined operations by eliminating 120 hrs/week of manual data compilation and directly enabled &gt;$1 billion in annual quota attainment. Instituted and governed the unified metrics definition for the CCO‚Äôs Monthly Business Review (MBR) and Weekly Readouts. This established the single source of truth for growth and profitability, driving cross-organizational consensus at the C-level within the Comcast ecosystem Integrated ML-driven risk models into core commercial workflows to proactively highlight emerging portfolio risks and attention gaps, accelerating critical high-value commercial decisions by 48 hours and improving resource targeting\n\n\nPython\n\n\nTableau\n\n\nAWS\n\n\n‚ö° IMPACT: 20+ HOURS SAVED / WEEK\nAutomated reporting pipelines using Python and SQL, eliminating manual bottleneck for the executive team."
  },
  {
    "objectID": "index.html#freewheel-active-role",
    "href": "index.html#freewheel-active-role",
    "title": "HELLO, I‚ÄôM NICK.",
    "section": "FREEWHEEL ACTIVE ROLE",
    "text": "FREEWHEEL ACTIVE ROLE\nACTIVE ROLE  ### Lead Analyst ‚Ä¢ 2025-Present\nACTIVE ROLE  * Founded, architected, and governed the analytics function for a 0-to-1 Commercial Operations business unit. Served as the primary C-Suite advisor to the Chief Commercial Officer (CCO), directing strategic decision support and scaling performance measurement across six sales organizations. &gt; &gt; &gt; Architected the end-to-end Sales Performance Monitoring ecosystem, deploying real-time pacing and KPI dashboards across six distinct sales organizations. This initiative streamlined operations by eliminating 120 hrs/week of manual data compilation and directly enabled &gt;$1 billion in annual quota attainment. Instituted and governed the unified metrics definition for the CCO‚Äôs Monthly Business Review (MBR) and Weekly Readouts. This established the single source of truth for growth and profitability, driving cross-organizational consensus at the C-level within the Comcast ecosystem Integrated ML-driven risk models into core commercial workflows to proactively highlight emerging portfolio risks and attention gaps, accelerating critical high-value commercial decisions by 48 hours and improving resource targeting\n\nPython\n\n\nTableau\n\n\nAWS\n\n\n‚ö° IMPACT: 20+ HOURS SAVED / WEEK\nAutomated reporting pipelines using Python and SQL, eliminating manual bottleneck for the executive team."
  },
  {
    "objectID": "posts/mazes.html",
    "href": "posts/mazes.html",
    "title": "Common Search Algorithms Applied to Mazes",
    "section": "",
    "text": "Maze & Pathing Generator\nData viz ‚Ä¢ Javascript ‚Ä¢ D3.js \n\nData Viz\n\n\n\nA 20x20 maze generated using Prim‚Äôs minimum spanning tree algorithm. Navigate using common search algorithms to visualize how each finds the solution.\nEvery time you click RUN, a new random maze is formed.\n\n\nüïπÔ∏è CONTROLS\n Select an Algorithm Breadth First Search Depth First Search \n\nRUN ALGORITHM"
  },
  {
    "objectID": "posts/ab-test.html",
    "href": "posts/ab-test.html",
    "title": "Marketing A/B Test",
    "section": "",
    "text": "Python ‚Ä¢ Stats  \n\nBuisness Case\nFor this analysis, we‚Äôll examine customer churn results based on an A/B test. We‚Äôll pull our data from a CSV into a pandas dataframe."
  },
  {
    "objectID": "posts/ab-test.html#executive-summary",
    "href": "posts/ab-test.html#executive-summary",
    "title": "Marketing A/B Test",
    "section": "‚ö° EXECUTIVE SUMMARY",
    "text": "‚ö° EXECUTIVE SUMMARY\nWe tested a new ‚ÄúSingle-Page Checkout‚Äù against the baseline. The test reached statistical significance (\\(p &lt; 0.05\\)) with a 4.2% lift in conversion, representing a potential $200k ARR increase"
  },
  {
    "objectID": "posts/ab-test.html#recommendations",
    "href": "posts/ab-test.html#recommendations",
    "title": "Marketing A/B Test",
    "section": "üöÄ RECOMMENDATIONS",
    "text": "üöÄ RECOMMENDATIONS\n\nFull Rollout: Deploy the variant to 100% of traffic.\nMonitor LTV: Track these users for 90 days to ensure ‚ÄúEasy Checkout‚Äù doesn‚Äôt increase return rates.\nIterate: Test ‚ÄúGuest Checkout‚Äù next to further reduce friction."
  },
  {
    "objectID": "posts/edaclust.html",
    "href": "posts/edaclust.html",
    "title": "Unveiling Hidden Patterns",
    "section": "",
    "text": "The Goal: Identify non-obvious store performance trends to assist marketing budget allocation.\nThe Result: Successfully segmented stores into 4 distinct performance clusters validated by ANOVA (\\(p &lt; 0.001\\)) and a strong effect size (Cohen‚Äôs \\(d &gt; 0.8\\))."
  },
  {
    "objectID": "posts/edaclust.html#executive-summary",
    "href": "posts/edaclust.html#executive-summary",
    "title": "Unveiling Hidden Patterns",
    "section": "",
    "text": "The Goal: Identify non-obvious store performance trends to assist marketing budget allocation.\nThe Result: Successfully segmented stores into 4 distinct performance clusters validated by ANOVA (\\(p &lt; 0.001\\)) and a strong effect size (Cohen‚Äôs \\(d &gt; 0.8\\))."
  },
  {
    "objectID": "posts/edaclust.html#the-hypothetical",
    "href": "posts/edaclust.html#the-hypothetical",
    "title": "Unveiling Hidden Patterns",
    "section": "üìã The Hypothetical",
    "text": "üìã The Hypothetical\n\nPrompt: A marketing decision-maker needs to determine if there are trends across store performance that aren‚Äôt initially obvious.\n\nWe are working with Walmart sales data. While limited in scope, this serves as a critical Exploratory Data Analysis (EDA) to justify deeper segmentation marketing strategies.\nimport pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt from scipy.stats import f_oneway from sklearn.metrics import silhouette_score from scipy.cluster import hierarchy"
  },
  {
    "objectID": "posts/mktlogit.html",
    "href": "posts/mktlogit.html",
    "title": "Predicting Marketing Success",
    "section": "",
    "text": "The Objective: Determine if Education level serves as a primary driver for marketing campaign acceptance.\nKey Finding: While Education initially appears significant, it is actually a proxy for Income. Income maintains a high correlation (0.82) with total spend and acts as a statistically significant predictor in logistic regression."
  },
  {
    "objectID": "posts/mktlogit.html#executive-summary",
    "href": "posts/mktlogit.html#executive-summary",
    "title": "Predicting Marketing Success",
    "section": "",
    "text": "The Objective: Determine if Education level serves as a primary driver for marketing campaign acceptance.\nKey Finding: While Education initially appears significant, it is actually a proxy for Income. Income maintains a high correlation (0.82) with total spend and acts as a statistically significant predictor in logistic regression."
  },
  {
    "objectID": "posts/mktlogit.html#project-motivation",
    "href": "posts/mktlogit.html#project-motivation",
    "title": "Predicting Marketing Success",
    "section": "üìã Project Motivation",
    "text": "üìã Project Motivation\nUsing a dataset provided by iFood, we examine the relationship between a user‚Äôs educational background and their likelihood to accept marketing offers."
  },
  {
    "objectID": "posts/causality.html",
    "href": "posts/causality.html",
    "title": "Causality",
    "section": "",
    "text": "Machine Learning ‚Ä¢ Python ‚Ä¢ Stats  \n\nBuisness Case"
  },
  {
    "objectID": "posts/causality.html#executive-summary",
    "href": "posts/causality.html#executive-summary",
    "title": "Causality",
    "section": "‚ö° EXECUTIVE SUMMARY",
    "text": "‚ö° EXECUTIVE SUMMARY\nThe Challenge: Engineered a high-performance pipeline to process 30GB of unstructured customer data into a clean analytical layer. The goal was to isolate the causal impact of ‚ÄúAuto-Renew‚Äù features on churn, moving beyond simple correlation.\nThe Engineering: Leveraged DuckDB for lightning-fast local processing of large-scale Parquet/JSON files and dbt for modular, version-controlled transformations and data modeling.\nThe Analytics: Applied Double Machine Learning (DoubleML) to account for self-selection bias, identifying a 5% causal lift in retention directly attributable to auto-billing.\nThe Outcome: Successfully isolated a 5% causal lift in retention by de-biasing the ‚ÄúSelf-Selection‚Äù effect (where loyalists are naturally more likely to opt-in). This provides a statistically sound foundation for projecting the ROI of auto-billing incentives. Robustness checks via DoubleML‚Äôs orthogonalization confirmed that the effect remained significant even after controlling for 15+ high-dimensional confounding variables (Income, Tenure, Usage Frequency)."
  },
  {
    "objectID": "posts/causality.html#recommendations",
    "href": "posts/causality.html#recommendations",
    "title": "Causality",
    "section": "üöÄ RECOMMENDATIONS",
    "text": "üöÄ RECOMMENDATIONS\n\nFollowup Testing: A/B Lift test to validate results and see if churn can be impacted further through direct action\nDevelop KPI: Assess auto-renew rates as a measure of account health and churn likelihoods.\nIterate: Investigate UI methods to incentive auto-renew enablement."
  },
  {
    "objectID": "posts/causality.html#methods",
    "href": "posts/causality.html#methods",
    "title": "Causality",
    "section": "‚ö° Methods",
    "text": "‚ö° Methods\nStep 1 (Nuisance Models): Using Random Forests to predict who is likely to choose auto-renew based on demographics.\nStep 2 (Orthogonalization): Removing that ‚Äúpredictable‚Äù part to look only at the unexpected behavior.\nStep 3 (The Estimator): Running the final causal model on the ‚Äúcleaned‚Äù data. the KKbox dataset we were working in is in the realm of 30gigs in total of mostly unstructured data. In order to perform any sort of analysis or ML on this data, we need some sort of ETL process completed to ensure clean features are being passed to the model.\nIn order to solve this problem, I loaded the raw data into duckdb and used dbt to create pipelines pulling from the raw csv, applying cleanliness steps, and ultimately delivering a features table for the followup ML work.\nThe ML work is done through querying the clean features table and using the Histogram Gradient Boosters from scikit-learn. THe work was also validated through a placebo test which showed that overfitting not driving the good results we saw.\nModel 1: Predicting the Treatment (Who chooses Auto-Renew?).\nModel 2: Predicting the Outcome (Who Churns?). The Challenge: Selection Bias (The ‚ÄúWhy‚Äù) This is where you show your seniority. Explain the Confounding Variable.\nExplain that ‚ÄúPower Users‚Äù are more likely to both (A) stay long-term and (B) turn on auto-renew.\nA simple regression would ‚Äúover-credit‚Äù auto-renew because it‚Äôs picking up on the user‚Äôs pre-existing loyalty.\nThe Residuals: Analyzing the ‚Äúunexplained‚Äù part of both to find the true causal effect. $200k ARR increase\nimport pandas as pd\nimport math\n\ndf = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\") \n# Index(['user id', 'test group', 'converted', 'total ads', 'most ads day', 'most ads hour'])"
  },
  {
    "objectID": "posts/causality.html#methods-1",
    "href": "posts/causality.html#methods-1",
    "title": "Causality",
    "section": "‚ö° Methods",
    "text": "‚ö° Methods\nStep 1 (Nuisance Models): Using Random Forests to predict who is likely to choose auto-renew based on demographics.\nStep 2 (Orthogonalization): Removing that ‚Äúpredictable‚Äù part to look only at the unexpected behavior.\nStep 3 (The Estimator): Running the final causal model on the ‚Äúcleaned‚Äù data. the KKbox dataset we were working in is in the realm of 30gigs in total of mostly unstructured data. In order to perform any sort of analysis or ML on this data, we need some sort of ETL process completed to ensure clean features are being passed to the model.\nIn order to solve this problem, I loaded the raw data into duckdb and used dbt to create pipelines pulling from the raw csv, applying cleanliness steps, and ultimately delivering a features table for the followup ML work.\nThe ML work is done through querying the clean features table and using the Histogram Gradient Boosters from scikit-learn. THe work was also validated through a placebo test which showed that overfitting not driving the good results we saw."
  },
  {
    "objectID": "posts/causality.html#the-data-pipeline",
    "href": "posts/causality.html#the-data-pipeline",
    "title": "Causality",
    "section": "‚ö° The Data Pipeline",
    "text": "‚ö° The Data Pipeline\nI utilized DuckDB to process the 30GB dataset locally, avoiding the overhead and cost of a cloud warehouse while maintaining sub-minute query performance on large-scale unstructured files.\nExtraction: Processing 30GB of unstructured logs.\nProcessing: Using DuckDB as an OLAP engine to aggregate data in seconds rather than hours.\nTransformation: dbt models for feature engineering (creating the ‚ÄúNuisance‚Äù variables like tenure, usage frequency, and income proxies).\nModeling: DoubleML via Python."
  },
  {
    "objectID": "posts/causality copy.html",
    "href": "posts/causality copy.html",
    "title": "Designing a Unified KPI Framework for Enterprise Decision-Making",
    "section": "",
    "text": "Buisness Case"
  },
  {
    "objectID": "posts/causality copy.html#executive-summary",
    "href": "posts/causality copy.html#executive-summary",
    "title": "Designing a Unified KPI Framework for Enterprise Decision-Making",
    "section": "‚ö° EXECUTIVE SUMMARY",
    "text": "‚ö° EXECUTIVE SUMMARY\nThe Chief Commercial Officer lacked a consistent, trusted monthly view of performance across four commercial business units, limiting effective resource allocation and executive decision-making. Metric definitions varied by organization, data sources conflicted, and gaps in coverage meant leadership reviews were dominated by reconciling conflicting numbers rather than evaluating tradeoffs or setting direction.\nI designed and led the establishment of a standardized monthly business review, defining shared metric foundations, baseline KPIs, and performance narratives that scaled across business units and created a durable executive-level decision surface."
  },
  {
    "objectID": "posts/causality copy.html#methods",
    "href": "posts/causality copy.html#methods",
    "title": "Causality",
    "section": "‚ö° Methods",
    "text": "‚ö° Methods\nStep 1 (Nuisance Models): Using Random Forests to predict who is likely to choose auto-renew based on demographics.\nStep 2 (Orthogonalization): Removing that ‚Äúpredictable‚Äù part to look only at the unexpected behavior.\nStep 3 (The Estimator): Running the final causal model on the ‚Äúcleaned‚Äù data. the KKbox dataset we were working in is in the realm of 30gigs in total of mostly unstructured data. In order to perform any sort of analysis or ML on this data, we need some sort of ETL process completed to ensure clean features are being passed to the model.\nIn order to solve this problem, I loaded the raw data into duckdb and used dbt to create pipelines pulling from the raw csv, applying cleanliness steps, and ultimately delivering a features table for the followup ML work.\nThe ML work is done through querying the clean features table and using the Histogram Gradient Boosters from scikit-learn. THe work was also validated through a placebo test which showed that overfitting not driving the good results we saw.\nModel 1: Predicting the Treatment (Who chooses Auto-Renew?).\nModel 2: Predicting the Outcome (Who Churns?). The Challenge: Selection Bias (The ‚ÄúWhy‚Äù) This is where you show your seniority. Explain the Confounding Variable.\nExplain that ‚ÄúPower Users‚Äù are more likely to both (A) stay long-term and (B) turn on auto-renew.\nA simple regression would ‚Äúover-credit‚Äù auto-renew because it‚Äôs picking up on the user‚Äôs pre-existing loyalty.\nThe Residuals: Analyzing the ‚Äúunexplained‚Äù part of both to find the true causal effect. $200k ARR increase\nimport pandas as pd\nimport math\n\ndf = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\") \n# Index(['user id', 'test group', 'converted', 'total ads', 'most ads day', 'most ads hour'])"
  },
  {
    "objectID": "posts/causality copy.html#the-data-pipeline",
    "href": "posts/causality copy.html#the-data-pipeline",
    "title": "Causality",
    "section": "‚ö° The Data Pipeline",
    "text": "‚ö° The Data Pipeline\nI utilized DuckDB to process the 30GB dataset locally, avoiding the overhead and cost of a cloud warehouse while maintaining sub-minute query performance on large-scale unstructured files.\nExtraction: Processing 30GB of unstructured logs.\nProcessing: Using DuckDB as an OLAP engine to aggregate data in seconds rather than hours.\nTransformation: dbt models for feature engineering (creating the ‚ÄúNuisance‚Äù variables like tenure, usage frequency, and income proxies).\nModeling: DoubleML via Python."
  },
  {
    "objectID": "posts/causality copy.html#recommendations",
    "href": "posts/causality copy.html#recommendations",
    "title": "Causality",
    "section": "üöÄ RECOMMENDATIONS",
    "text": "üöÄ RECOMMENDATIONS\n\nFollowup Testing: A/B Lift test to validate results and see if churn can be impacted further through direct action\nDevelop KPI: Assess auto-renew rates as a measure of account health and churn likelihoods.\nIterate: Investigate UI methods to incentive auto-renew enablement."
  },
  {
    "objectID": "posts/causality copy.html#problems-and-constraints",
    "href": "posts/causality copy.html#problems-and-constraints",
    "title": "Designing a Unified KPI Framework for Enterprise Decision-Making",
    "section": "‚ö° Problems and Constraints",
    "text": "‚ö° Problems and Constraints\nThis effort operated within a low data- and analytics-maturity environment, where many stakeholders lacked shared mental models for key KPIs and had limited tolerance for technical or methodological detail. Metrics that were analytically sound often failed in practice unless they could be explained quickly and consistently at the executive level.\nAs a result, KPI definitions required multiple iterations to balance analytical rigor with interpretability, and most metrics had to be expressed at a deliberately high level to enable cross-organizational comparison. Detailed diagnostics and follow-up analyses were intentionally separated into appendices, preserving simplicity in executive forums while maintaining analytical depth for downstream investigation. Over successive review cycles, this structure created a shared vocabulary for performance, reducing iteration cycles and increasing the pace of executive decision-making."
  },
  {
    "objectID": "posts/causality copy.html#metrics-definition-ownership",
    "href": "posts/causality copy.html#metrics-definition-ownership",
    "title": "Causality",
    "section": "‚ö° Metrics & Definition Ownership",
    "text": "‚ö° Metrics & Definition Ownership\nI utilized DuckDB to process the 30GB dataset locally, avoiding the overhead and cost of a cloud warehouse while maintaining sub-minute query performance on large-scale unstructured files.\nExtraction: Processing 30GB of unstructured logs.\nProcessing: Using DuckDB as an OLAP engine to aggregate data in seconds rather than hours.\nTransformation: dbt models for feature engineering (creating the ‚ÄúNuisance‚Äù variables like tenure, usage frequency, and income proxies).\nModeling: DoubleML via Python."
  },
  {
    "objectID": "posts/causality copy.html#what-id-improve",
    "href": "posts/causality copy.html#what-id-improve",
    "title": "Designing a Unified KPI Framework for Enterprise Decision-Making",
    "section": "üöÄ What I‚Äôd Improve",
    "text": "üöÄ What I‚Äôd Improve\nWhile the monthly business review achieved consistent, trusted executive reporting, subsequent iterations revealed opportunities to accelerate adoption and increase interpretability. I would prioritize defining business and KPI definitions upfront with each VP organization, ensuring alignment on meaning and intent before building the review, which would reduce iteration cycles and enable faster delivery of actionable insights. Additionally, I would allocate more energy to support each VP in developing their organizational narratives, creating a stronger link between metrics and decision-making at the unit level. Finally, embedding optional explanatory context directly within the review or appendix‚Äîclarifying assumptions, variance drivers, and methodology‚Äîcould further enhance interpretability and reduce reliance on ad hoc analyst explanations.\n   &lt;ul&gt;\n   Introduce mini-onboarding materials for each VP org so they can interpret metrics independently.\nInclude standardized variance explanations for each KPI, reducing analyst intervention.\nSet up proactive feedback loops with leadership to identify metrics that need refinement each quarter."
  },
  {
    "objectID": "posts/causality copy.html#design-principles",
    "href": "posts/causality copy.html#design-principles",
    "title": "Designing a Unified KPI Framework for Enterprise Decision-Making",
    "section": "‚ö° Design Principles",
    "text": "‚ö° Design Principles\nInterpretability over local optimization. Metrics were designed to be immediately interpretable at the executive level, even when this required simplifying analytically richer measures. If a KPI could not be explained consistently across organizations, it was not suitable for inclusion in the core review.\nUnified definitions with layered rollups. Core metric definitions and KPIs were standardized across commercial organizations, with each business unit contributing metrics that rolled up into a coherent enterprise-level view. This allowed leadership to reason about the full business while preserving traceability down to individual org performance.\nComparability before completeness. Metrics were selected and scoped to enable reliable cross-org comparison, even when this meant deferring more detailed or org-specific analyses to appendices. The primary review optimized for alignment and decision-making, not exhaustiveness.\nLow-maintenance by default. Tables, charts, and narratives were designed as reusable, automated components delivered on a fixed monthly cadence. This minimized manual rework, reduced ongoing maintenance cost, and ensured the analytics team remained focused on interpretation and decision support rather than report recreation. Over time, this structure reduced ongoing maintenance effort and created space for deeper analysis, as the monthly review no longer required ad hoc rebuilds or metric renegotiation."
  },
  {
    "objectID": "posts/Unified_KPI.html",
    "href": "posts/Unified_KPI.html",
    "title": "Designing a Unified KPI Framework for Enterprise Decision-Making",
    "section": "",
    "text": "Buisness Case"
  },
  {
    "objectID": "posts/Unified_KPI.html#executive-summary",
    "href": "posts/Unified_KPI.html#executive-summary",
    "title": "Designing a Unified KPI Framework for Enterprise Decision-Making",
    "section": "‚ö° EXECUTIVE SUMMARY",
    "text": "‚ö° EXECUTIVE SUMMARY\nThe Chief Commercial Officer lacked a consistent, trusted monthly view of performance across four commercial business units, limiting effective resource allocation and executive decision-making. Metric definitions varied by organization, data sources conflicted, and gaps in coverage meant leadership reviews were dominated by reconciling conflicting numbers rather than evaluating tradeoffs or setting direction.\nI designed and led the establishment of a standardized monthly business review, defining shared metric foundations, baseline KPIs, and performance narratives that scaled across business units and created a durable executive-level decision surface."
  },
  {
    "objectID": "posts/Unified_KPI.html#problems-and-constraints",
    "href": "posts/Unified_KPI.html#problems-and-constraints",
    "title": "Designing a Unified KPI Framework for Enterprise Decision-Making",
    "section": "‚ö° Problems and Constraints",
    "text": "‚ö° Problems and Constraints\nThis effort operated within a low data- and analytics-maturity environment, where many stakeholders lacked shared mental models for key KPIs and had limited tolerance for technical or methodological detail. Metrics that were analytically sound often failed in practice unless they could be explained quickly and consistently at the executive level.\nAs a result, KPI definitions required multiple iterations to balance analytical rigor with interpretability, and most metrics had to be expressed at a deliberately high level to enable cross-organizational comparison. Detailed diagnostics and follow-up analyses were intentionally separated into appendices, preserving simplicity in executive forums while maintaining analytical depth for downstream investigation. Over successive review cycles, this structure created a shared vocabulary for performance, reducing iteration cycles and increasing the pace of executive decision-making."
  },
  {
    "objectID": "posts/Unified_KPI.html#design-principles",
    "href": "posts/Unified_KPI.html#design-principles",
    "title": "Designing a Unified KPI Framework for Enterprise Decision-Making",
    "section": "‚ö° Design Principles",
    "text": "‚ö° Design Principles\nInterpretability over local optimization. Metrics were designed to be immediately interpretable at the executive level, even when this required simplifying analytically richer measures. If a KPI could not be explained consistently across organizations, it was not suitable for inclusion in the core review.\nUnified definitions with layered rollups. Core metric definitions and KPIs were standardized across commercial organizations, with each business unit contributing metrics that rolled up into a coherent enterprise-level view. This allowed leadership to reason about the full business while preserving traceability down to individual org performance.\nComparability before completeness. Metrics were selected and scoped to enable reliable cross-org comparison, even when this meant deferring more detailed or org-specific analyses to appendices. The primary review optimized for alignment and decision-making, not exhaustiveness.\nLow-maintenance by default. Tables, charts, and narratives were designed as reusable, automated components delivered on a fixed monthly cadence. This minimized manual rework, reduced ongoing maintenance cost, and ensured the analytics team remained focused on interpretation and decision support rather than report recreation. Over time, this structure reduced ongoing maintenance effort and created space for deeper analysis, as the monthly review no longer required ad hoc rebuilds or metric renegotiation."
  },
  {
    "objectID": "posts/Unified_KPI.html#what-id-improve",
    "href": "posts/Unified_KPI.html#what-id-improve",
    "title": "Designing a Unified KPI Framework for Enterprise Decision-Making",
    "section": "üöÄ What I‚Äôd Improve",
    "text": "üöÄ What I‚Äôd Improve\nWhile the monthly business review achieved consistent, trusted executive reporting, subsequent iterations revealed opportunities to accelerate adoption and increase interpretability. I would prioritize defining business and KPI definitions upfront with each VP organization, ensuring alignment on meaning and intent before building the review, which would reduce iteration cycles and enable faster delivery of actionable insights. Additionally, I would allocate more energy to support each VP in developing their organizational narratives, creating a stronger link between metrics and decision-making at the unit level. Finally, embedding optional explanatory context directly within the review or appendix‚Äîclarifying assumptions, variance drivers, and methodology‚Äîcould further enhance interpretability and reduce reliance on ad hoc analyst explanations. Introduce mini-onboarding materials for each VP org so they can interpret metrics independently. Include standardized variance explanations for each KPI, reducing analyst intervention. Set up proactive feedback loops with leadership to identify metrics that need refinement each quarter."
  },
  {
    "objectID": "posts/Unified_KPI.html#the-chief-commercial-officer-lacked-a-consistent-trusted-monthly-view-of-performance",
    "href": "posts/Unified_KPI.html#the-chief-commercial-officer-lacked-a-consistent-trusted-monthly-view-of-performance",
    "title": "Designing a Unified KPI Framework for Enterprise Decision-Making",
    "section": "The Chief Commercial Officer lacked a consistent, trusted monthly view of performance",
    "text": "The Chief Commercial Officer lacked a consistent, trusted monthly view of performance\nacross four commercial business units, limiting effective resource allocation and executive decision-making. Metric definitions varied by organization, data sources conflicted, and gaps in coverage meant leadership reviews were dominated by reconciling conflicting numbers rather than evaluating tradeoffs or setting direction.\nI designed and led the establishment of a standardized monthly business review, defining shared metric foundations, baseline KPIs, and performance narratives that scaled across business units and created a durable executive-level decision surface."
  },
  {
    "objectID": "index.html#areas-of-impact",
    "href": "index.html#areas-of-impact",
    "title": "HELLO, I‚ÄôM NICK.",
    "section": "üõ†Ô∏è Areas of Impact",
    "text": "üõ†Ô∏è Areas of Impact\n\n\n\nExecutive Decision Support & KPI Governance\n\nTranslating complex commercial and product data into trusted executive decisions\n\nTrusted advisor to C-suite and VP leadership on revenue architecture and KPI design\n\n\nOwnership of SSOT logic for executive MBRs across global sales organizations\n\n\nResolution of cross-functional metric conflicts through shared definitions and governance\n\n\nDecision framing for quota management, forecasting, and long-range planning\n\n\n\n\n\n\n\nForecasting, Experimentation & Risk Modeling\n\nEnabling proactive decisions under uncertainty\n\nProbabilistic demand and revenue forecasting for capacity and budget planning\n\n\nValidation frameworks to support high-stakes resource allocation decisions\n\n\nScenario analysis and risk modeling for operational optimization\n\n\nTools: Python, SQL, scikit-learn, Prophet\n\n\n\n\n\n\n\n\nProductized Analytics & Data Platforms\n\nBuilding analytics systems that scale decision-making\n\nArchitected centralized analytics platforms serving sales, product, and operations\n\n\nProductized Python- and SQL-based analytics used by hundreds of stakeholders\n\n\nEnabled self-service analytics while preserving data quality and governance\n\n\nTools: BigQuery, Snowflake, dbt, Python, Airflow-style orchestration\n\n\n\n\n\n\n\nData Architecture, Quality & Governance\n\nEnsuring trust, scale, and consistency in enterprise analytics\n\nMetric standardization, lineage, and metadata governance\n\n\nDesign of scalable data models for petabyte-scale datasets\n\n\nPrivacy-safe analytics architecture and compliance leadership\n\n\nTools: dbt, Snowflake, BigQuery, SQL optimization\n\n\n\n\n\n\n\n\nCross-Functional Leadership & Influence\n\nLeading through influence across product, engineering, and commercial teams\n\nFounding analytics lead for new orgs and initiatives\n\n\nAlignment of Sales, Finance, Product, and Engineering on shared data strategy\n\n\nTechnical mentorship and enablement for global teams\n\n\nOrg-wide standards and best-practice development\n\n\n\n\n\n\n\nStrategic Translation & Storytelling\n\nTurning analysis into clear, defensible narratives\n\nExecutive-level decision memos and readouts\n\n\nTradeoff framing and scenario communication\n\n\nTranslation of statistical uncertainty into business action\n\n\nStakeholder-ready storytelling for technical and non-technical audiences"
  },
  {
    "objectID": "index.html#project-four",
    "href": "index.html#project-four",
    "title": "HELLO, I‚ÄôM NICK.",
    "section": "PROJECT FOUR",
    "text": "PROJECT FOUR\nNeural Network Viz An interactive dashboard using PyTorch and Shiny. Visualizes how weights change during backpropagation in real-time."
  },
  {
    "objectID": "index.html#designing-a-unified-kpi-framework-for-enterprise-decision-making",
    "href": "index.html#designing-a-unified-kpi-framework-for-enterprise-decision-making",
    "title": "HELLO, I‚ÄôM NICK.",
    "section": "Designing a Unified KPI Framework for Enterprise Decision-Making",
    "text": "Designing a Unified KPI Framework for Enterprise Decision-Making\n\nStandardized monthly business review ‚Üí unified metrics across 4 business units, cut prep from 2 weeks to 2 hours, enabling C-suite focus on decisions.\nVIEW PROJECT"
  },
  {
    "objectID": "index.html#global-diagnostic-etl-engine-google",
    "href": "index.html#global-diagnostic-etl-engine-google",
    "title": "HELLO, I‚ÄôM NICK.",
    "section": "##Global Diagnostic & ETL Engine | Google",
    "text": "##Global Diagnostic & ETL Engine | Google\nNeural Network Viz An interactive dashboard using PyTorch and Shiny. Visualizes how weights change during backpropagation in real-time.\nVIEW PROJECT"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Causality\n\n\nStatistical Significance Analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCommon Search Algorithms Applied to Mazes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDesigning a Unified KPI Framework for Enterprise Decision-Making\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMarketing A/B Test\n\n\nStatistical Significance Analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredicting Marketing Success\n\n\nAn Analysis of Education and Income as Predictors of Campaign Receptivity\n\n\n\n\n\n\n\n\nYour Name\n\n\n\n\n\n\n\n\n\n\n\n\nProject One: Housing Price Predictor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTwo\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnveiling Hidden Patterns\n\n\nClustering and Statistical Validation of Walmart Store Sales\n\n\n\n\n\n\n\n\nYour Name\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#google",
    "href": "index.html#google",
    "title": "HELLO, I‚ÄôM NICK.",
    "section": "Google",
    "text": "Google\n\nAutomated anomaly detection for 250+ engineers, reducing MTTR 30% and improving operational insights\nVIEW PROJECT\n\nCase Study"
  }
]